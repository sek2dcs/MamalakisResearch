{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff961e62",
   "metadata": {},
   "source": [
    "## Data Sources and Import Statements\n",
    "\n",
    "Data have been downloaded from the Earth System Grid Federation at https://esgf-node.ipsl.upmc.fr/projects/esgf-ipsl/.\n",
    "\n",
    "Each file has been concatenated to contain ssp119 and ssp126 scenarios and r1-5 ensemble members from 2015 to 2100. Each has also been regridded to 2.5° resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35d685f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-31 19:04:55.551382: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Caroline/miniconda3/envs/mamalakis/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "2.18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Caroline/miniconda3/envs/mamalakis/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# IMPORT STATEMENTS\n",
    "\n",
    "# General useful libraries\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "# Loading in data (netcdf files)\n",
    "import h5py\n",
    "# Handling data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "# Installing xarray and its dependencies\n",
    "import xarray as xr\n",
    "import scipy \n",
    "import dask\n",
    "import bottleneck\n",
    "# Plotting figures\n",
    "import matplotlib.pyplot as plt # Main plotting package\n",
    "from matplotlib.ticker import MultipleLocator # Supporting plotting package \n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.util import add_cyclic_point\n",
    "import cartopy.mpl.ticker as cticker\n",
    "# Machine Learning package\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_v2_behavior() \n",
    "print(tf.__version__)\n",
    "# Interpreting neural networks \n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5a753b",
   "metadata": {},
   "source": [
    "## Loading Data/Checking Shape & Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8839b0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lat', 'lon', 'time', 'data_ssp119', 'data_ssp126']\n"
     ]
    }
   ],
   "source": [
    "# Replace this line with the folder in which your clone of the repo is located\n",
    "os.chdir(\"/Users/Caroline/Desktop/school/MamalakisResearch\")\n",
    "\n",
    "base_path = os.getcwd()\n",
    "\n",
    "data_path = base_path + \"/data/\"\n",
    "\n",
    "# Move to the data folder\n",
    "os.chdir(\"data\")\n",
    "\n",
    "filenames = [\n",
    "    \"CNRM_ESM2-1_ssp119_ssp126_201501_210012_r1-5_2pt5degree.nc\",\n",
    "    \"MIROC6_ssp119_ssp126_201501_210012_r1-5_2pt5degree.nc\",\n",
    "    \"MPI-ESM1-2-LR_ssp119_ssp126_201501_210012_r1-5_2pt5degree.nc\",\n",
    "    \"MRI-ESM2-0_ssp119_ssp126_201501_210012_r1-5_2pt5degree.nc\",\n",
    "    \"UKESM1-0-LL_ssp119_ssp126_201501_210012_r1-5_2pt5degree.nc\",\n",
    "]\n",
    "\n",
    "# We will call upon this later when loading files\n",
    "files = [os.path.join(data_path, f) for f in filenames]\n",
    "\n",
    "ds = nc.Dataset(files[0])\n",
    "print(list(ds.variables.keys()))\n",
    "ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b20a950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_ssp119 shape: (5, 7, 1032, 144, 73)\n",
      "data_ssp126 shape: (5, 7, 1032, 144, 73)\n",
      "data_ssp119 dims: ('ensemble', 'variable', 'time', 'lon', 'lat')\n",
      "data_ssp126 dims: ('ensemble', 'variable', 'time', 'lon', 'lat')\n"
     ]
    }
   ],
   "source": [
    "ds = nc.Dataset(files[0])\n",
    "\n",
    "print(\"data_ssp119 shape:\", ds[\"data_ssp119\"].shape)\n",
    "print(\"data_ssp126 shape:\", ds[\"data_ssp126\"].shape)\n",
    "\n",
    "print(\"data_ssp119 dims:\", ds[\"data_ssp119\"].dimensions)\n",
    "print(\"data_ssp126 dims:\", ds[\"data_ssp126\"].dimensions)\n",
    "\n",
    "ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa1a1502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 234.47755571890667 309.8531804281488 270.3023092874373\n",
      "1 236.21079545127867 322.26223186661866 274.1879111830409\n",
      "2 232.61641495096973 301.92593328821147 266.7963481147974\n",
      "3 2.125162459204466e-12 0.00026221260865620655 1.8725814006290823e-05\n",
      "4 98075.16364846689 103840.45692411123 100618.62371195715\n",
      "5 0.0015542857193698485 12.37257435270109 2.7059935880144472\n",
      "6 3.1505518403209596 45.331031811593704 28.4120984137752\n"
     ]
    }
   ],
   "source": [
    "ds = nc.Dataset(files[1])\n",
    "x = np.array(ds[\"data_ssp119\"][0, :, 0, :, :])  # (7, lon, lat)\n",
    "for i in range(x.shape[0]):\n",
    "    print(i, np.nanmin(x[i]), np.nanmax(x[i]), np.nanmean(x[i]))\n",
    "ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d5a6914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitude range: 0.0 to 357.5\n",
      "Latitude range: -90.0 to 90.0\n"
     ]
    }
   ],
   "source": [
    "# Confirm the min and max lon and lat\n",
    "ds = nc.Dataset(files[1])\n",
    "\n",
    "# Get the actual lon/lat coordinate arrays\n",
    "lon = np.array(ds[\"lon\"][:])\n",
    "lat = np.array(ds[\"lat\"][:])\n",
    "\n",
    "# Find min and max\n",
    "lon_min, lon_max = np.nanmin(lon), np.nanmax(lon)\n",
    "lat_min, lat_max = np.nanmin(lat), np.nanmax(lat)\n",
    "\n",
    "print(f\"Longitude range: {lon_min} to {lon_max}\")\n",
    "print(f\"Latitude range: {lat_min} to {lat_max}\")\n",
    "\n",
    "# Longitude max is 357.5 degrees which accounts for 2.5 degree grid resolution; 360 degrees would be the same location as 0 degrees\n",
    "\n",
    "ds.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8250e9f0",
   "metadata": {},
   "source": [
    "## Variable Index Map and Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f58b1ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable order is explicitly given by metadata:\n",
    "# \"tas, tasmax, tasmin, pr, psl, sfcWind, mrsos\"\n",
    "var_to_index = {\n",
    "    \"tas\": 0,\n",
    "    \"tasmax\": 1,\n",
    "    \"tasmin\": 2,\n",
    "    \"pr\": 3,\n",
    "    \"psl\": 4,\n",
    "    \"sfcWind\": 5,\n",
    "    \"mrsos\": 6,\n",
    "}\n",
    "\n",
    "# Units are also given:\n",
    "var_units = {\n",
    "    \"tas\": \"K\",\n",
    "    \"tasmax\": \"K\",\n",
    "    \"tasmin\": \"K\",\n",
    "    \"pr\": \"kg/m2s\",\n",
    "    \"psl\": \"Pa\",\n",
    "    \"sfcWind\": \"m/s\",\n",
    "    \"mrsos\": \"kg/m2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbee2d8",
   "metadata": {},
   "source": [
    "## Time Handling (Monthly Index → Years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0142cac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(path: str) -> str:\n",
    "    # Everything before \"_ssp...\"\n",
    "    return os.path.basename(path).split(\"_ssp\")[0]\n",
    "\n",
    "\n",
    "def months_to_year_month(time_months: np.ndarray, start_year=2015, start_month=1):\n",
    "    \"\"\"\n",
    "    File says time units are 'months' and it spans 2015-2100.\n",
    "    This creates year + month arrays assuming the first index corresponds to Jan 2015.\n",
    "\n",
    "    If my time axis is \"month count since 2015-01\", this is correct.\n",
    "    If not, it still gives consistent indexing as long as the file starts at 2015-01.\n",
    "    \"\"\"\n",
    "    # time_months is usually 0..1031 or 1..1032 depending on how the file was written but I handle either by shifting to 0-based.\n",
    "    t = np.array(time_months, dtype=int)\n",
    "    if t.min() == 1:\n",
    "        t = t - 1\n",
    "\n",
    "    # compute year/month\n",
    "    year = start_year + (start_month - 1 + t) // 12\n",
    "    month = (start_month - 1 + t) % 12 + 1\n",
    "    return year, month\n",
    "\n",
    "\n",
    "def time_mask_for_year_range(ds: nc.Dataset, start_year: int, end_year: int):\n",
    "    \"\"\"\n",
    "    Create a mask over the monthly time axis using year bounds.\n",
    "    \"\"\"\n",
    "    t = ds[\"time\"][:]\n",
    "    year, month = months_to_year_month(t, start_year=2015, start_month=1)\n",
    "    return (year >= start_year) & (year <= end_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c97e9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(path: str) -> str:\n",
    "    # Everything before \"_ssp...\"\n",
    "    return os.path.basename(path).split(\"_ssp\")[0]\n",
    "\n",
    "\n",
    "def months_to_year_month(time_months: np.ndarray, start_year=2015, start_month=1):\n",
    "    \"\"\"\n",
    "    File says time units are 'months' and it spans 2015-2100.\n",
    "    This creates year + month arrays assuming the first index corresponds to Jan 2015.\n",
    "    \"\"\"\n",
    "    # Cast to numpy array in case it's passed as an xarray DataArray\n",
    "    t = np.array(time_months, dtype=int)\n",
    "    \n",
    "    # Handle 1-based vs 0-based indexing by shifting to 0-based\n",
    "    if t.min() == 1:\n",
    "        t = t - 1\n",
    "\n",
    "    # Compute year/month using floor division and modulo\n",
    "    year = start_year + (start_month - 1 + t) // 12\n",
    "    month = (start_month - 1 + t) % 12 + 1\n",
    "    return year, month\n",
    "\n",
    "\n",
    "def time_mask_for_year_range(ds: xr.Dataset, start_year: int, end_year: int):\n",
    "    \"\"\"\n",
    "    Create a mask over the monthly time axis using year bounds.\n",
    "    \"\"\"\n",
    "    # Using .values to pull the underlying numpy array from the xarray object\n",
    "    t = ds[\"time\"].values\n",
    "    \n",
    "    # Conversion logic\n",
    "    year, month = months_to_year_month(t, start_year=2015, start_month=1)\n",
    "    \n",
    "    # Returning the boolean mask as a numpy array \n",
    "    return (year >= start_year) & (year <= end_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de03746f",
   "metadata": {},
   "source": [
    "## Unit Conversions and Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bb0b5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_units(varname: str, x: np.ndarray) -> tuple[np.ndarray, str]:\n",
    "    \"\"\"\n",
    "    Convert raw units into more interpretable and plottable units.\n",
    "    - tas/tasmax/tasmin: K to C\n",
    "    - pr: kg/m2s to mm/day  (1 kg/m2 = 1 mm water; multiply by 86400)\n",
    "    - psl: Pa to hPa\n",
    "    - sfcWind: keep m/s\n",
    "    - mrsos: keep kg/m2 \n",
    "    \"\"\"\n",
    "    if varname in {\"tas\", \"tasmax\", \"tasmin\"}:\n",
    "        return x - 273.15, \"°C\"\n",
    "    if varname == \"pr\":\n",
    "        return x * 86400.0, \"mm/day\"\n",
    "    if varname == \"psl\":\n",
    "        return x / 100.0, \"hPa\"\n",
    "    if varname == \"sfcWind\":\n",
    "        return x, \"m/s\"\n",
    "    if varname == \"mrsos\":\n",
    "        return x, \"kg/m²\"\n",
    "    return x, \"unknown\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6f9a88",
   "metadata": {},
   "source": [
    "## Statistics Functions (Mean, Std, Median, Percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f6b52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_normalized_stat_over_time(base_x: np.ndarray, x: np.ndarray, stat: str = \"mean\", remove_seasonality=True) -> tuple:\n",
    "    \"\"\"\n",
    "    x: (ens, time) after spatial averaging\n",
    "    Returns: tuple of (data, stat) both with seasonality removed if requested\n",
    "      - For use with normalized time series plot\n",
    "      - Default: Average the monthly temperature values to generate an annual time series for each realization at each grid point\n",
    "    Supported stats:\n",
    "      - mean (default)\n",
    "      - std\n",
    "      - median\n",
    "      - percentile_XX  (ex. percentile_95)\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the base period overall average\n",
    "    base_ensemble_avg = np.nanmean(base_x, axis=0)\n",
    "    base_avg = np.nanmean(base_ensemble_avg, axis=0)\n",
    "\n",
    "    s = stat.lower().strip()\n",
    "    m = re.match(r\"percentile[_\\s-]?(\\d+)\", s)\n",
    "\n",
    "    if s == \"mean\":\n",
    "        # Find the statistic\n",
    "        x_stat = np.nanmean(x, axis=0) # Axis = 0 bc x has shape (ensemble, time) --> output will be time series of shape (time,)\n",
    "        # Subtract the base period average from each value\n",
    "\n",
    "    elif s == \"std\":\n",
    "        x_stat = np.nanstd(x, axis=0) - base_avg\n",
    "    elif s == \"median\":\n",
    "        x_stat = np.nanmedian(x, axis=0) - base_avg\n",
    "    elif m:\n",
    "        p = float(m.group(1))\n",
    "        x_stat = np.nanpercentile(x, p, axis=0) - base_avg\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown stat '{stat}'. Use mean/std/median/percentile_XX.\")\n",
    "\n",
    "    # Seasonality check\n",
    "    if remove_seasonality:\n",
    "        # Dimensions of x are # ensembles, # months; reshape to mean over months (ens, years, 12)\n",
    "        x_rs = np.nanmean(x.values.reshape(x.shape[0], x.shape[1] // 12, 12), axis=2) - base_avg\n",
    "        x_stat_rs = np.nanmean(x_stat.reshape(-1, 12), axis=1)\n",
    "        return x_rs, x_stat_rs\n",
    "    else:\n",
    "        return x - base_avg, x_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d036b20",
   "metadata": {},
   "source": [
    "## Loading and Aggregating Data for One Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be85ceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_manipulate_dataset(\n",
    "    varname: str,\n",
    "    scenario: str,\n",
    "    model_name: str,\n",
    "    base_period: tuple[int, int] | None = (2015, 2024),\n",
    "    period: tuple[int, int] | None = (2015, 2100),\n",
    "    region: tuple[int, int, int, int] | None = None\n",
    "): \n",
    "\n",
    "    \"\"\"\n",
    "    Opens and manipulates given dataset for a chosen scenario, base period, time period, and region. For use in normalized time series plots.\n",
    "    \"\"\"\n",
    "\n",
    "    # Scenario check\n",
    "    scenario = scenario.lower()\n",
    "    if scenario not in {\"ssp119\", \"ssp126\"}:\n",
    "        raise ValueError(\"scenario must be 'ssp119' or 'ssp126'\")\n",
    "\n",
    "    key = f\"data_{scenario}\"\n",
    "    vidx = var_to_index[varname]\n",
    "\n",
    "    # Opening dataset \n",
    "    ds = xr.open_dataset(model_name, engine=\"netcdf4\")\n",
    "\n",
    "    # Unpacking period tuples \n",
    "    base_start, base_end = base_period\n",
    "    start_year, end_year = period\n",
    "    if start_year < base_start:\n",
    "        raise ValueError(\"Model year cannot start before base period start year.\")\n",
    "    if end_year < base_end:\n",
    "        raise ValueError(\"Model year cannot end before base period end year.\")\n",
    "\n",
    "    # Subsetting time\n",
    "    if base_period is not None:\n",
    "        base_mask = time_mask_for_year_range(ds, base_start, base_end) \n",
    "        if base_mask.sum() == 0:\n",
    "            ds.close()\n",
    "            raise ValueError(f\"No months found between {base_start}-{base_end} in {model_name}\")\n",
    "\n",
    "    if period is not None:\n",
    "        mask = time_mask_for_year_range(ds, start_year, end_year) \n",
    "        if mask.sum() == 0:\n",
    "            ds.close()\n",
    "            raise ValueError(f\"No months found between {start_year}-{end_year} in {model_name}\")\n",
    "\n",
    "    # Raw shapes: (ensemble, var, time, lon, lat)\n",
    "    base_raw = ds[key].isel(variable=vidx).sel(time=base_mask)\n",
    "    raw = ds[key].isel(variable=vidx).sel(time=mask)\n",
    "\n",
    "    # Extract actual start and end years from the filtered data for the base period\n",
    "    actual_times = base_raw.time.values\n",
    "    year, month = months_to_year_month(actual_times)\n",
    "    base_start = int(year[0])\n",
    "    base_end = int(year[-1])\n",
    "\n",
    "    # Extract actual start and end years from the filtered data for the time period\n",
    "    actual_times = raw.time.values\n",
    "    year, month = months_to_year_month(actual_times)\n",
    "    start_year = int(year[0])\n",
    "    end_year = int(year[-1])\n",
    "\n",
    "    # Transpose to (ensemble, time, lat, lon) from (ensemble, time, lon, lat) \n",
    "    base_array = base_raw.transpose(\"ensemble\", \"time\", \"lat\", \"lon\")\n",
    "    data_array = raw.transpose(\"ensemble\", \"time\", \"lat\", \"lon\")\n",
    "\n",
    "    # Converting units\n",
    "    base_array, unit_label = convert_units(varname, base_array)\n",
    "    data_array, unit_label = convert_units(varname, data_array)\n",
    "\n",
    "    # Subsetting regions\n",
    "    if region is not None:\n",
    "        lat1, lat2, lon1, lon2 = region\n",
    "        base_array = base_array.sel(lat=slice(lat1, lat2), lon=slice(lon1, lon2))\n",
    "        data_array = data_array.sel(lat=slice(lat1, lat2), lon=slice(lon1, lon2))\n",
    "    else:\n",
    "        # Define these for the return statement if no region is provided\n",
    "        lat1, lat2, lon1, lon2 = ds.lat.min(), ds.lat.max(), ds.lon.min(), ds.lon.max()\n",
    "    \n",
    "    # Applying cosine logic, thus weighting the average since grid cells get smaller toward the poles\n",
    "    base_cosl = np.cos(np.pi * base_array.lat / 180)\n",
    "    cosl = np.cos(np.pi * data_array.lat / 180)\n",
    "    \n",
    "    # Spatial averaging\n",
    "    base_ts = base_array.weighted(base_cosl).mean(dim=(\"lat\", \"lon\"))\n",
    "    processed_base_data = base_ts.compute()\n",
    "\n",
    "    ts = data_array.weighted(cosl).mean(dim=(\"lat\", \"lon\"))\n",
    "    processed_data = ts.compute()\n",
    "\n",
    "    # Assigning a name to each file for future plotting - take everything before the first instance of \"_ssp\"\n",
    "    # Replace with Hayeon's function\n",
    "    split_str = re.split(\"_ssp\", model_name, 1)\n",
    "    model_name_short = split_str[0]\n",
    "\n",
    "    # Assigning a name to each variable\n",
    "    if varname == \"tas\":\n",
    "        varname_long = \"Near-Surface Air Temperature (Deg C)\"\n",
    "    elif varname == \"tasmax\":\n",
    "        varname_long = \"Daily Maximum Near-Surface Air Temperature (Deg C)\"\n",
    "    elif varname == \"tasmin\":\n",
    "        varname_long = \"Daily Minimum Near-Surface Air Temperature (Deg C)\"\n",
    "    elif varname == \"pr\":\n",
    "        varname_long = \"Precipitation (mm/day)\"\n",
    "    elif varname == \"psl\":\n",
    "        varname_long = \"Sea Level Pressure (Pa)\"\n",
    "    elif varname == \"sfcWind\": \n",
    "        varname_long = \"Surface Wind Speed (m/s)\",\n",
    "    elif varname == \"mrsos\":\n",
    "        varname_long = \"Moisture in Upper Portion of Soil Column (kg/m²)\"\n",
    "    else:\n",
    "        varname_long = \"Unknown variable (no units given)\"\n",
    "\n",
    "    ds.close()\n",
    "\n",
    "    # \"Repack\" tuple\n",
    "    region = (float(lat1), float(lat2), float(lon1), float(lon2))\n",
    "\n",
    "    return processed_base_data, processed_data, base_start, base_end, start_year, end_year, region, model_name_short, varname_long"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf7cb6b",
   "metadata": {},
   "source": [
    "## Normalized Time Series Plot\n",
    "\n",
    "Produces a plot of a time series from 2015 to 2100 for the selected variable, scenario, and model. Will show all 5 trajectories within a model. \n",
    "Data are normalized against a given baseline period so that the data shown are in comparison to that baseline period's average.\n",
    "All stats shown will be anomolies relative to that base period provided.\n",
    "\n",
    "Inputs: \n",
    "- Variable\n",
    "- Scenario\n",
    "- Base period (2015-2024 default)\n",
    "- Time period (2015-2100 default)\n",
    "- Region (entire globe default, lon/lat range)\n",
    "- Statistic\n",
    "- Number models returned (all 5 default, single model name) \n",
    "- File name(s)\n",
    "- Whether to remove seasonality via annual averaging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8caa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_time_series_plot(\n",
    "    varname: str,\n",
    "    scenario: str | list[str] | None = [\"ssp119\", \"ssp126\"],\n",
    "    base_period: tuple[int, int] | None = (2015, 2024),\n",
    "    period: tuple[int, int] | None = (2015, 2100),\n",
    "    region: tuple[int, int, int, int] | None = None,\n",
    "    stat: str = \"mean\",\n",
    "    multimodel: bool = True,\n",
    "    model_name: str | list[str] | None = None,\n",
    "    remove_seasonality: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Produces a time series plot where the inputs are:\n",
    "      varname: one of tas, tasmax, tasmin, pr, psl, sfcWind, mrsos\n",
    "      scenario: both ssp119 and 126 scenarios (default) or \"ssp119\" or \"ssp126\" \n",
    "      base_period: 2015-2024 (default), (start_year, end_year)\n",
    "      period: 2015-2100 (default), (start_year, end_year)\n",
    "      region: entire globe (default), lon/lat range\n",
    "      stat: mean (default), std, median, percentile_XX\n",
    "      multimodel: True (average across all 5 models) (default)\n",
    "      model_name: if not None, ignore multimodel and plot only that/those model(s)\n",
    "      remove_seasonality: True (default), False\n",
    "    \"\"\"\n",
    "\n",
    "    # Variable check\n",
    "    if varname not in var_to_index:\n",
    "        raise ValueError(f\"varname must be one of {list(var_to_index.keys())}\")\n",
    "    \n",
    "    # Scenario check\n",
    "    if isinstance(scenario, str):\n",
    "        scenario = [scenario]\n",
    "    scenario = [s.lower() for s in scenario]\n",
    "    for s in scenario:\n",
    "        if s not in {\"ssp119\", \"ssp126\"}:\n",
    "            raise ValueError(\"Scenario(s) must be chosen from 'ssp119' or 'ssp126'.\")\n",
    "\n",
    "    # Model name check\n",
    "    file_list = []\n",
    "\n",
    "    # Option 1: if a model name is given and multimodel is false\n",
    "    if model_name and not multimodel:\n",
    "        # In case user passed a single string, wrapping it in a list\n",
    "        if isinstance(model_name, str):\n",
    "            model_name = [model_name]\n",
    "        # Filtering to only available files\n",
    "        for m in model_name:\n",
    "            if m in filenames:\n",
    "                file_list.append(m)\n",
    "            else: \n",
    "                raise ValueError(f\"model {m} not found. Available: {filenames}.\")\n",
    "        # When a model name is given, don't calculate ensemble averaging\n",
    "        calculate_multimodel_ensemble = False\n",
    "  \n",
    "    # Option 2: if multimodel=True and no model names given\n",
    "    elif not model_name and multimodel:\n",
    "        file_list = filenames\n",
    "        calculate_multimodel_ensemble = True\n",
    "\n",
    "    # Option 3: if multimodel=True and model names given\n",
    "    elif model_name and multimodel:\n",
    "        # Should we do ensemble average over just the models given? For now, raise error\n",
    "        raise ValueError(\"Multimodel cannot be true if model names are given. Please set multimodel=False or set model_name=None.\")\n",
    "\n",
    "    # Option 4: multimodel=False and model names not given\n",
    "    else:\n",
    "        raise ValueError(\"Must provide at least one model name or set multimodel=True.\")\n",
    "\n",
    "    # Initializing figure and needed variables\n",
    "    plt.figure(figsize=(10,6))\n",
    "    color_idx = 0\n",
    "    varname_long_display = \"\"\n",
    "\n",
    "    for s in scenario:\n",
    "\n",
    "        # Storing individual model stats for the average and setting a group color and current time axis\n",
    "        multimodel_ensemble_data = [] \n",
    "        group_color = f'C{color_idx % 10}'\n",
    "        current_time_axis = None\n",
    "\n",
    "        # Pulling variables from normalize_manipulate_dataset function\n",
    "        for f in file_list: \n",
    "            # _ for the region output avoids overwriting the input 'region' variable\n",
    "            base_processed_data, processed_data, base_start, base_end, start_year, end_year, _, model_name_short, varname_long = normalize_manipulate_dataset(varname, s, f, base_period, period, region)\n",
    "            varname_long_display = varname_long\n",
    "            \n",
    "            # Calculating the chosen stat for the individual model\n",
    "            if remove_seasonality: \n",
    "                all_data, computed_stat = compute_normalized_stat_over_time(processed_data, stat) # Default is to remove seasonality\n",
    "                # Creating a time axis to match the yearly data length\n",
    "                yr_time_axis = np.linspace(start_year, end_year + 1, processed_data.shape[1]//12, endpoint=False)\n",
    "                current_time_axis = yr_time_axis\n",
    "\n",
    "            else:\n",
    "                all_data, computed_stat = compute_normalized_stat_over_time(processed_data, stat, remove_seasonality=False)\n",
    "                # Creating a time axis to match the monthly data length\n",
    "                mth_time_axis = np.linspace(start_year, end_year + 1, processed_data.shape[1], endpoint=False)\n",
    "                current_time_axis = mth_time_axis\n",
    "\n",
    "            # If multimodel flag is on: \n",
    "            if calculate_multimodel_ensemble:\n",
    "                plt.plot(current_time_axis, computed_stat, color=group_color, alpha=0.3, label='_nolegend_')\n",
    "                multimodel_ensemble_data.append(computed_stat)\n",
    "            \n",
    "            # If multimodel flag is not on (i.e., specific model(s) was/were requested), plot each run for each model as well as the computed stat for each model \n",
    "            else:\n",
    "                plt.plot(current_time_axis, all_data.T, color=f'C{color_idx % 10}', alpha=0.3, label='_nolegend_')\n",
    "                plt.plot(current_time_axis, computed_stat, color=f'C{color_idx % 10}', linewidth=3, label=f\"{model_name_short} {stat.capitalize()} {s.upper()}\")\n",
    "                color_idx+=1\n",
    "\n",
    "        # If multimodel flag is on (and array to store the models' data is not empty), calculate and plot the average of all models\n",
    "        if calculate_multimodel_ensemble and multimodel_ensemble_data:\n",
    "            # Stack models and take the mean across the model axis (axis 0)\n",
    "            ensemble_avg = np.mean(np.array(multimodel_ensemble_data), axis=0)\n",
    "            plt.plot(current_time_axis, ensemble_avg, color=group_color, linewidth=3, label=f\"Ensemble Mean {stat.capitalize()} {s.upper()}\")\n",
    "            color_idx+=1\n",
    "\n",
    "    # Setting the time axis grid points to every 10 years (decadal) unless span is only 10 years or fewer\n",
    "    if end_year - start_year > 10:\n",
    "        plt.gca().xaxis.set_major_locator(MultipleLocator(10))\n",
    "    elif 5 < end_year - start_year < 10: \n",
    "        plt.gca().xaxis.set_major_locator(MultipleLocator(5))\n",
    "    else: \n",
    "        plt.gca().xaxis.set_major_locator(MultipleLocator(1))\n",
    "\n",
    "    plt.xlabel('Year')\n",
    "    if remove_seasonality:\n",
    "        plt.ylabel(f\"{stat.capitalize()} {varname_long_display} (Annual Means)\")\n",
    "    else:\n",
    "        plt.ylabel(f\"{stat.capitalize()} {varname_long_display}\")\n",
    "    plt.axis('tight')\n",
    "    plt.grid(color='0.8')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa51f59c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 9, got 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m    \u001b[38;5;66;03m# Example 1: Time-series of mean tas in ssp119 scenario for single CNRM model from 2020 to 2039\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43mnormalized_time_series_plot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvarname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtas\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscenario\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mssp119\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mperiod\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2020\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2039\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mregion\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstat\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmultimodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCNRM_ESM2-1_ssp119_ssp126_201501_210012_r1-5_2pt5degree.nc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43mremove_seasonality\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 83\u001b[39m, in \u001b[36mnormalized_time_series_plot\u001b[39m\u001b[34m(varname, scenario, base_period, period, region, stat, multimodel, model_name, remove_seasonality)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m# Pulling variables from manipulate_dataset function\u001b[39;00m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m file_list: \n\u001b[32m     82\u001b[39m     \u001b[38;5;66;03m# _ for the region output avoids overwriting the input 'region' variable\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     base_processed_data, processed_data, base_start, base_end, start_year, end_year, _, model_name_short, varname_long = manipulate_dataset(varname, s, f, base_period, period, region)\n\u001b[32m     84\u001b[39m     varname_long_display = varname_long\n\u001b[32m     86\u001b[39m     \u001b[38;5;66;03m# Calculating the chosen stat for the individual model\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: not enough values to unpack (expected 9, got 6)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "   # Example 1: Time-series of mean tas in ssp119 scenario for single CNRM model from 2020 to 2039\n",
    "    normalized_time_series_plot(\n",
    "        varname=\"tas\",\n",
    "        scenario=\"ssp119\", \n",
    "        period=(2020, 2039), \n",
    "        region=None,\n",
    "        stat=\"mean\",\n",
    "        multimodel=False,\n",
    "        model_name = \"CNRM_ESM2-1_ssp119_ssp126_201501_210012_r1-5_2pt5degree.nc\",\n",
    "        remove_seasonality = True\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mamalakis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
