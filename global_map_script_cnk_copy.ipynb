{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35d685f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ds6001/lib/python3.13/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/miniconda3/envs/ds6001/lib/python3.13/site-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "2.20.0\n"
     ]
    }
   ],
   "source": [
    "# IMPORT STATEMENTS\n",
    "\n",
    "#General Python math functions\n",
    "import math\n",
    "#Loading in data (netcdf files)\n",
    "import h5py\n",
    "#Handling data\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "#Plotting figures\n",
    "import matplotlib.pyplot as plt #Main plotting package\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.util import add_cyclic_point\n",
    "import cartopy.mpl.ticker as cticker\n",
    "\n",
    "#Machine Learning package\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_v2_behavior() \n",
    "print(tf.__version__)\n",
    "\n",
    "#Interpreting neural networks \n",
    "import  shap\n",
    "\n",
    "\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af6d2a1",
   "metadata": {},
   "source": [
    "## Path & Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa208bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "BASE_PATH = \"/Users/hayeonchung/Downloads/Mamalakis Graduate Research/\"\n",
    "\n",
    "FILES = [\n",
    "    \"CNRM_ESM2-1_ssp119_ssp126_201501_210012_r1-5_2pt5degree (1).nc\",\n",
    "    \"MIROC6_ssp119_ssp126_201501_210012_r1-5_2pt5degree (1).nc\",\n",
    "    \"MPI-ESM1-2-LR_ssp119_ssp126_201501_210012_r1-5_2pt5degree (1).nc\",\n",
    "    \"MRI-ESM2-0_ssp119_ssp126_201501_210012_r1-5_2pt5degree (1).nc\",\n",
    "    \"UKESM1-0-LL_ssp119_ssp126_201501_210012_r1-5_2pt5degree (1).nc\",\n",
    "]\n",
    "FILES = [os.path.join(BASE_PATH, f) for f in FILES]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f7760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"/Users/Caroline/Desktop/school/MamalakisResearch/data\"\n",
    "\n",
    "FILES = [\n",
    "    \"CNRM_ESM2-1_ssp119_ssp126_201501_210012_r1-5_2pt5degree.nc\",\n",
    "    \"MIROC6_ssp119_ssp126_201501_210012_r1-5_2pt5degree.nc\",\n",
    "    \"MPI-ESM1-2-LR_ssp119_ssp126_201501_210012_r1-5_2pt5degree.nc\",\n",
    "    \"MRI-ESM2-0_ssp119_ssp126_201501_210012_r1-5_2pt5degree.nc\",\n",
    "    \"UKESM1-0-LL_ssp119_ssp126_201501_210012_r1-5_2pt5degree.nc\",\n",
    "]\n",
    "\n",
    "FILES = [os.path.join(BASE_PATH, f) for f in FILES]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8250e9f0",
   "metadata": {},
   "source": [
    "## Variable Index Map and Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f58b1ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable order is explicitly given by metadata:\n",
    "# \"tas, tasmax, tasmin, pr, psl, sfcWind, mrsos\"\n",
    "VAR_TO_INDEX = {\n",
    "    \"tas\": 0,\n",
    "    \"tasmax\": 1,\n",
    "    \"tasmin\": 2,\n",
    "    \"pr\": 3,\n",
    "    \"psl\": 4,\n",
    "    \"sfcWind\": 5,\n",
    "    \"mrsos\": 6,\n",
    "}\n",
    "\n",
    "# Units are also given:\n",
    "VAR_UNITS = {\n",
    "    \"tas\": \"K\",\n",
    "    \"tasmax\": \"K\",\n",
    "    \"tasmin\": \"K\",\n",
    "    \"pr\": \"kg/m2s\",\n",
    "    \"psl\": \"Pa\",\n",
    "    \"sfcWind\": \"m/s\",\n",
    "    \"mrsos\": \"kg/m2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbee2d8",
   "metadata": {},
   "source": [
    "## Time Handling (Monthly Index → Years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0142cac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(path: str) -> str:\n",
    "    # Everything before \"_ssp...\"\n",
    "    return os.path.basename(path).split(\"_ssp\")[0]\n",
    "\n",
    "\n",
    "def months_to_year_month(time_months: np.ndarray, start_year=2015, start_month=1):\n",
    "    \"\"\"\n",
    "    File says time units are 'months' and it spans 2015-2100.\n",
    "    This creates year + month arrays assuming the first index corresponds to Jan 2015.\n",
    "\n",
    "    If my time axis is \"month count since 2015-01\", this is correct.\n",
    "    If not, it still gives consistent indexing as long as the file starts at 2015-01.\n",
    "    \"\"\"\n",
    "    # time_months is usually 0..1031 or 1..1032 depending on how the file was written but I handle either by shifting to 0-based.\n",
    "    t = np.array(time_months, dtype=int)\n",
    "    if t.min() == 1:\n",
    "        t = t - 1\n",
    "\n",
    "    # compute year/month\n",
    "    year = start_year + (start_month - 1 + t) // 12  \n",
    "    month = (start_month - 1 + t) % 12 + 1 # check why it's plus one \n",
    "    return year, month\n",
    "\n",
    "\n",
    "def time_mask_for_year_range(ds: nc.Dataset, start_year: int, end_year: int):\n",
    "    \"\"\"\n",
    "    Create a mask over the monthly time axis using year bounds.\n",
    "    \"\"\"\n",
    "    t = ds[\"time\"][:]\n",
    "    year, month = months_to_year_month(t, start_year=2015, start_month=1)\n",
    "    return (year >= start_year) & (year <= end_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de03746f",
   "metadata": {},
   "source": [
    "## Unit Conversions and Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bb0b5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_units(varname: str, x: np.ndarray) -> tuple[np.ndarray, str]:\n",
    "    \"\"\"\n",
    "    Convert raw units into nicer plotting/interpretation units.\n",
    "    - tas/tasmax/tasmin: K to C\n",
    "    - pr: kg/m2s to mm/day  (1 kg/m2 = 1 mm water; multiply by 86400)\n",
    "    - psl: Pa to hPa\n",
    "    - sfcWind: keep m/s\n",
    "    - mrsos: keep kg/m2 \n",
    "    \"\"\"\n",
    "    if varname in {\"tas\", \"tasmax\", \"tasmin\"}:\n",
    "        return x - 273.15, \"°C\"\n",
    "    if varname == \"pr\":\n",
    "        return x * 86400.0, \"mm/day\"\n",
    "    if varname == \"psl\":\n",
    "        return x / 100.0, \"hPa\"\n",
    "    if varname == \"sfcWind\":\n",
    "        return x, \"m/s\"\n",
    "    if varname == \"mrsos\":\n",
    "        return x, \"kg/m²\"\n",
    "    return x, \"unknown\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6f9a88",
   "metadata": {},
   "source": [
    "## Statistics Functions (Mean, Std, Median, Percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48c2f5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stat_over_time(x: np.ndarray, stat: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    x: (ens, time, lat, lon) after loading and swapping\n",
    "    Returns: (ens, lat, lon) after aggregating over time\n",
    "    Supported stats:\n",
    "      - mean (default)\n",
    "      - std\n",
    "      - median\n",
    "      - percentile_XX  (ex. percentile_95)\n",
    "    \"\"\"\n",
    "    s = stat.lower().strip()\n",
    "\n",
    "    if s == \"mean\":\n",
    "        return np.nanmean(x, axis=1) # axis=1 refers to the time dimension, np.namean ignores the missing values\n",
    "    if s == \"std\":\n",
    "        return np.nanstd(x, axis=1)\n",
    "    if s == \"median\":\n",
    "        return np.nanmedian(x, axis=1)\n",
    "\n",
    "    m = re.match(r\"percentile[_\\s-]?(\\d+)\", s) # re.match matches the pattern at the beginning of the string and [] matches any character inside the brackets\n",
    "    if m: # true only if user asked for a percentile value\n",
    "        p = float(m.group(1)) # extract the percentile value from the matched pattern\n",
    "        return np.nanpercentile(x, p, axis=1) # compute the percentile over time \n",
    "\n",
    "    raise ValueError(f\"Unknown stat '{stat}'. Use mean/std/median/percentile_XX.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f76405",
   "metadata": {},
   "source": [
    "## Loading and Aggregating Data for One Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34e6a47",
   "metadata": {},
   "source": [
    "### Essentially what this does: From one climate model file, extract one variable, for one scenario, over a specific time window, and return a single spatial map that represents a statistic (mean, max, etc.) averaged across ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "778d88d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_period_map(\n",
    "    file_path: str,\n",
    "    scenario: str,\n",
    "    varname: str,\n",
    "    start_year: int,\n",
    "    end_year: int,\n",
    "    stat: str = \"mean\",\n",
    ") -> tuple[np.ndarray, np.ndarray, np.ndarray, str]:\n",
    "    \"\"\"\n",
    "    Load a model, select scenario & variable, subset time range, compute stat map.\n",
    "    Returns:\n",
    "      lat (lat,), lon (lon,), map (lat, lon), unit_label\n",
    "    \"\"\"\n",
    "    scenario = scenario.lower()\n",
    "    if scenario not in {\"ssp119\", \"ssp126\"}:\n",
    "        raise ValueError(\"scenario must be 'ssp119' or 'ssp126'\")\n",
    "\n",
    "    key = f\"data_{scenario}\"\n",
    "    vidx = VAR_TO_INDEX[varname]\n",
    "\n",
    "    ds = nc.Dataset(file_path)\n",
    "\n",
    "    lat = np.array(ds[\"lat\"][:]) # extracting latitude and longitude grids\n",
    "    lon = np.array(ds[\"lon\"][:])\n",
    "\n",
    "    # time subset (monthly)\n",
    "    mask = time_mask_for_year_range(ds, start_year, end_year) # creating a boolean mask that selects only the months between start_year and end_year\n",
    "    if mask.sum() == 0:\n",
    "        ds.close()\n",
    "        raise ValueError(f\"No months found between {start_year}-{end_year} in {file_path}\")\n",
    "\n",
    "    # raw shape: (ens, var, time, lon, lat)\n",
    "    raw = ds[key]\n",
    "\n",
    "    x = np.array(raw[:, vidx, mask, :, :], dtype=float)  # slicing the 5D array into (ens, time, lon, lat) by selecting scenario (key), variable (vidx), and time (mask)\n",
    "    ds.close()\n",
    "\n",
    "    # swap to (ens, time, lat, lon) from (ens, time, lon, lat) \n",
    "    x = x.swapaxes(-1, -2)\n",
    "\n",
    "    # unit conversion\n",
    "    x, unit_label = convert_units(varname, x)\n",
    "\n",
    "    # compute stat over time -> (ens, lat, lon) using the specified statistic to translate temporal information into climate signal by summarizing climate behavior over a definied period\n",
    "    ens_maps = compute_stat_over_time(x, stat)\n",
    "\n",
    "    # average across ensembles -> (lat, lon) by taking the mean of the ensembles\n",
    "    out_map = np.nanmean(ens_maps, axis=0)\n",
    "\n",
    "    return lat, lon, out_map, unit_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2769893f",
   "metadata": {},
   "source": [
    "## Plotting Global Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a048c45",
   "metadata": {},
   "source": [
    "### Essentially what this does: It takes a 2D global field (latitude × longitude) and produces a global map using a cartographic projection. By the time this function is called, all processing (model selection, unit conversion, temporal aggregation, ensemble averaging) is already done. This function is purely about visualizing the final result correctly and clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b3148c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_global_map(\n",
    "    lat,\n",
    "    lon,\n",
    "    field_latlon,\n",
    "    title,\n",
    "    unit_label=\"\",\n",
    "    symmetric=False,\n",
    "    vmin=None,\n",
    "    vmax=None,\n",
    "    maxabs=None,   # <-- NEW\n",
    "):\n",
    "    \"\"\"\n",
    "    field_latlon: (lat, lon)\n",
    "\n",
    "    - If symmetric=True:\n",
    "        * If maxabs is provided, uses [-maxabs, +maxabs]\n",
    "        * else computes maxabs from the current field (old behavior)\n",
    "    - If symmetric=False:\n",
    "        uses vmin/vmax if provided, else data-driven min/max\n",
    "    \"\"\"\n",
    "    field_cyc, lon_cyc = add_cyclic_point(field_latlon, coord=lon)\n",
    "\n",
    "    if symmetric:\n",
    "        if maxabs is None:\n",
    "            maxabs = float(np.nanmax(np.abs(field_cyc)))\n",
    "        vmin, vmax = -maxabs, maxabs\n",
    "        cmap = \"RdBu_r\"\n",
    "    else:\n",
    "        if vmin is None:\n",
    "            vmin = float(np.nanmin(field_cyc))\n",
    "        if vmax is None:\n",
    "            vmax = float(np.nanmax(field_cyc))\n",
    "        cmap = \"viridis\"\n",
    "\n",
    "    fig = plt.figure(figsize=(11, 4.5))\n",
    "    ax = plt.axes(projection=ccrs.Robinson())\n",
    "    ax.set_global()\n",
    "    ax.coastlines(linewidth=0.8)\n",
    "\n",
    "    mesh = ax.pcolormesh(\n",
    "        lon_cyc, lat, field_cyc,\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        shading=\"auto\",\n",
    "        vmin=vmin, vmax=vmax,\n",
    "        cmap=cmap\n",
    "    )\n",
    "\n",
    "    cbar = plt.colorbar(mesh, ax=ax, orientation=\"vertical\", pad=0.03, shrink=0.85)\n",
    "    if unit_label:\n",
    "        cbar.set_label(unit_label)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73452d53",
   "metadata": {},
   "source": [
    "## Script 1 Main Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b17d9c3",
   "metadata": {},
   "source": [
    "### This is the top-level function that accomplishes \"Given a variable, scenario, and time period(s), produce the correct global map.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f0f1ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global shared color scales \n",
    "GLOBAL_COLOR_SCALES = {}     # for absolute maps (vmin, vmax)\n",
    "GLOBAL_DIFF_MAXABS = {}      # for diff maps (maxabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "179c74ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def script1_global_map(\n",
    "    varname: str,\n",
    "    scenario: str,\n",
    "    period1: tuple[int, int],\n",
    "    period2: tuple[int, int] | None = None,\n",
    "    stat: str = \"mean\",\n",
    "    multimodel: bool = True,\n",
    "    model_name: str | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "      varname: one of tas, tasmax, tasmin, pr, psl, sfcWind, mrsos\n",
    "      scenario: \"ssp119\" or \"ssp126\"\n",
    "      period1: (start_year, end_year)\n",
    "      period2: (start_year, end_year) OR None\n",
    "      stat: mean (default), std, median, percentile_XX\n",
    "      multimodel: default True (average across all 5 models)\n",
    "      model_name: if not None, ignore multimodel and plot only that model\n",
    "\n",
    "    AUTOMATIC COLORBAR BEHAVIOR:\n",
    "      - For a given input (varname, stat, plot_type, tag), reuse the same vmin/vmax\n",
    "        across separate calls so maps are directly comparable \n",
    "      - plot_type is \"absolute\" (one-period maps) or \"diff\" (period2-period1)\n",
    "      - For diff maps already using symmetric=True, so vmin/vmax are ignored\n",
    "    \"\"\"\n",
    "\n",
    "    if varname not in VAR_TO_INDEX:\n",
    "        raise ValueError(f\"varname must be one of {list(VAR_TO_INDEX.keys())}\")\n",
    "    \n",
    "    if model_name is not None and multimodel:\n",
    "        raise ValueError(\n",
    "            \"Conflicting options: you set multimodel=True but also provided model_name. \"\n",
    "            \"Either set multimodel=False (single-model plot) or set model_name=None (multi-model mean).\"\n",
    "        )\n",
    "    if not multimodel and model_name is None:\n",
    "        raise ValueError(\n",
    "            \"Invalid options: multimodel=False requires a specific model_name to be provided.\"\n",
    "        )\n",
    "    # Choose files\n",
    "    selected_files = FILES\n",
    "    if model_name is not None:\n",
    "        selected_files = [fp for fp in FILES if get_model_name(fp) == model_name]\n",
    "        if len(selected_files) == 0:\n",
    "            raise ValueError(\n",
    "                f\"Model '{model_name}' not found. Available: {[get_model_name(f) for f in FILES]}\"\n",
    "            )\n",
    "\n",
    "    y1a, y1b = period1\n",
    "    # Validate period ordering (period1 must be earlier than period2)\n",
    "    if period2 is not None:\n",
    "        y2a, y2b = period2\n",
    "\n",
    "        if y1b >= y2a:\n",
    "            raise ValueError(\n",
    "                f\"Invalid period ordering: period1 ({y1a}–{y1b}) must be earlier than \"\n",
    "                f\"period2 ({y2a}–{y2b}).\"\n",
    "            )\n",
    "\n",
    "    unit_label = \"\"\n",
    "    lat_ref = lon_ref = None \n",
    "\n",
    "    # Helper: compute a period map, optionally multi-model average\n",
    "    def compute_period_map(start_y, end_y):\n",
    "        per_model = []\n",
    "        nonlocal unit_label, lat_ref, lon_ref\n",
    "\n",
    "        for fp in selected_files:\n",
    "            lat, lon, m, unit = load_model_period_map(\n",
    "                fp, scenario, varname, start_y, end_y, stat=stat # passing my local variable stat from load_model_period_map into the parameter named stat\n",
    "            )\n",
    "            if lat_ref is None:\n",
    "                lat_ref, lon_ref = lat, lon\n",
    "                unit_label = unit\n",
    "            per_model.append(m)\n",
    "\n",
    "        # If single model requested, just return that\n",
    "        if (model_name is not None) or (not multimodel):\n",
    "            return per_model[0]\n",
    "\n",
    "        # Multi-model mean\n",
    "        return np.nanmean(np.stack(per_model, axis=0), axis=0)\n",
    "\n",
    "    # Build a consistent tag (used in the scale key)\n",
    "    tag = model_name if model_name else (\"Multi-model mean\" if multimodel else \"Single model\")\n",
    "\n",
    "    map1 = compute_period_map(y1a, y1b)\n",
    "\n",
    "    # -----------------------\n",
    "    # ONE PERIOD CASE\n",
    "    # -----------------------\n",
    "    if period2 is None:\n",
    "        title = f\"{tag} | {scenario} | {varname} | {stat} | {y1a}-{y1b}\"\n",
    "\n",
    "        # AUTO-SHARED COLOR SCALE (absolute maps): Key ignores scenario so ssp119 and ssp126 share a scale for same var/stat/periods/tag\n",
    "        scale_key = (\"absolute\", tag, varname, stat, period1)\n",
    "\n",
    "        # Update running min/max for this key\n",
    "        vmin_new = float(np.nanmin(map1))\n",
    "        vmax_new = float(np.nanmax(map1))\n",
    "        if scale_key in GLOBAL_COLOR_SCALES:\n",
    "            vmin_old, vmax_old = GLOBAL_COLOR_SCALES[scale_key]\n",
    "            GLOBAL_COLOR_SCALES[scale_key] = (min(vmin_old, vmin_new), max(vmax_old, vmax_new))\n",
    "        else:\n",
    "            GLOBAL_COLOR_SCALES[scale_key] = (vmin_new, vmax_new)\n",
    "\n",
    "        vmin, vmax = GLOBAL_COLOR_SCALES[scale_key]\n",
    "\n",
    "        plot_global_map(\n",
    "            lat_ref, lon_ref, map1, title,\n",
    "            unit_label=unit_label,\n",
    "            symmetric=False,\n",
    "            vmin=vmin,\n",
    "            vmax=vmax\n",
    "        )\n",
    "        return\n",
    "\n",
    "    # -----------------------\n",
    "    # TWO PERIOD CASE: diff map\n",
    "    # -----------------------\n",
    "    y2a, y2b = period2\n",
    "    map2 = compute_period_map(y2a, y2b)\n",
    "    diff = map2 - map1\n",
    "\n",
    "    tag = model_name if model_name else (\"Multi-model mean\" if multimodel else \"Single model\")\n",
    "    title = f\"{tag} | {scenario} | {varname} | {stat} | ({y2a}-{y2b}) - ({y1a}-{y1b})\"\n",
    "\n",
    "# AUTO-SHARED SYMMETRIC SCALE FOR DIFF MAPS: Key ignores scenario so ssp119 and ssp126 share the same symmetric scale\n",
    "    diff_key = (\"diff\", tag, varname, stat, period1, period2)\n",
    "\n",
    "    maxabs_new = float(np.nanmax(np.abs(diff)))\n",
    "    if diff_key in GLOBAL_DIFF_MAXABS:\n",
    "        GLOBAL_DIFF_MAXABS[diff_key] = max(GLOBAL_DIFF_MAXABS[diff_key], maxabs_new)\n",
    "    else:\n",
    "        GLOBAL_DIFF_MAXABS[diff_key] = maxabs_new\n",
    "\n",
    "    shared_maxabs = GLOBAL_DIFF_MAXABS[diff_key]\n",
    "\n",
    "    plot_global_map(\n",
    "        lat_ref, lon_ref, diff, title,\n",
    "        unit_label=unit_label,\n",
    "        symmetric=True,\n",
    "        maxabs=shared_maxabs\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds6001",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
