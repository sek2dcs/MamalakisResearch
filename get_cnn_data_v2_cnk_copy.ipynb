{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6be7d098",
   "metadata": {},
   "source": [
    "## **prep**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66254658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages \n",
    "import os\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7191cc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to specific directory for user running code \n",
    "os.chdir(\"/Users/Caroline/Desktop/school/MamalakisResearch\") \n",
    "base_path = os.getcwd()\n",
    "\n",
    "# everyone should have locally loaded 'data' folder\n",
    "data_path = base_path + '/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ca6e6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing model list variable to call in function\n",
    "model_list = [\n",
    "    \"CNRM_ESM2-1_ssp119_ssp126_201501_210012_r1-5_2pt5degree.nc\",\n",
    "    \"MIROC6_ssp119_ssp126_201501_210012_r1-5_2pt5degree.nc\",\n",
    "    \"MPI-ESM1-2-LR_ssp119_ssp126_201501_210012_r1-5_2pt5degree.nc\",\n",
    "    \"MRI-ESM2-0_ssp119_ssp126_201501_210012_r1-5_2pt5degree.nc\",\n",
    "    \"UKESM1-0-LL_ssp119_ssp126_201501_210012_r1-5_2pt5degree.nc\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5034a455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pulling variables out for the plot function \n",
    "VAR_LIST = [\"tas\", \"tasmax\", \"tasmin\", \"pr\", \"psl\", \"sfcWind\", \"mrsos\"]\n",
    "\n",
    "# dictionary for each unit for the plot \n",
    "UNIT_MAP = {\n",
    "    \"tas\": \"°C\", \n",
    "    \"tasmax\": \"°C\", \n",
    "    \"tasmin\": \"°C\", \n",
    "    \"pr\": \"mm/day\", \n",
    "    \"psl\": \"hPa\", \n",
    "    \"sfcWind\": \"m/s\", \n",
    "    \"mrsos\": \"kg/m²\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933b1da1",
   "metadata": {},
   "source": [
    "## **functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb53951",
   "metadata": {},
   "source": [
    "### **converting units**\n",
    "\n",
    "*converting units for the variables*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "888043a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_units(varname: str, x: np.ndarray):\n",
    "    \"\"\"\n",
    "    varname: index number from the list of variables so get_data func can convert units \n",
    "    x: data that needs units changed (raw x data) in get_data func \n",
    "    \"\"\"\n",
    "    if varname in {\"tas\", \"tasmax\", \"tasmin\"}:\n",
    "        # kelvin to celcius\n",
    "        return x - 273.15, \"$^{\\circ}$C\"\n",
    "    if varname == \"pr\":\n",
    "        # kg/m2/s to mm/day\n",
    "        return x * 86400.0, \"mm/day\"\n",
    "    if varname == \"psl\":\n",
    "        # pascals to hpa\n",
    "        return x / 100.0, \"hPa\"\n",
    "    \n",
    "    # these don't need to be converted -- just adding the units \n",
    "    if varname == \"sfcWind\":\n",
    "        return x, \"m/s\"\n",
    "    if varname == \"mrsos\":\n",
    "        return x, \"kg/m$^{2}$\"\n",
    "    return x, \"unknown\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8193cf",
   "metadata": {},
   "source": [
    "### **cnn tensor prep**\n",
    "\n",
    "*calculates x_data tensor that calculates statistical summary for a certain variable (ie tas, tasmax, etc.) for specified early and late periods (also a baseline). can also calculate the difference between the early and late periods with the baseline yrs of 2015 and 2024. returns x_data tensor and y_data tensor (y_data tensor gives back a 2d tensor of [# of samples, 1] that gives binary labels (0 for early, 1 for late) for every variable value calculated)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1354cbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(path: str) -> str:\n",
    "    \"\"\"\n",
    "    helper function so that get_cnn_tensors prints out the models that are being processed\n",
    "    pulled from hayeon's code \n",
    "    \"\"\"\n",
    "    # Everything before \"_ssp...\"\n",
    "    return os.path.basename(path).split(\"_ssp\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42617e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_tensors(model_list, scenario, data_path, var_idx=\"all\", \n",
    "                    st_early=2015, end_early=2024, \n",
    "                    st_late=2050, end_late=2059,\n",
    "                    stat='mean', use_anomaly=True, \n",
    "                    base_start=2015, base_end=2024,\n",
    "                    models_to_run=None, file_start_year=2015):\n",
    "    \"\"\"\n",
    "    model_list: variable of list of models\n",
    "    scenario: input as either 'ssp119' or 'ssp126' strings\n",
    "    data_path: variable of data_path for user\n",
    "    var_idx: default is \"all\" (so all variables will be looked at). Or, 0-6 of the variable dimension of tensor \n",
    "        0: tas (near-surface air temp)\n",
    "        1: tasmax (near-surface air temp max)\n",
    "        2: tasmin (near-surface air temp min)\n",
    "        3: pr (precipitation)\n",
    "        4: psl (sea level pressure -- air pressure adjusted to sea level & drives weather patterns)\n",
    "        5: sfcWind (surface wind speed -- usually 10m above land surface)\n",
    "        6: mrsos (moisture in upper portion of soil col -- good for looking at agr & drought conditions)\n",
    "    st_early: early period start yr integer\n",
    "    end_early: early period end yr integer\n",
    "    st_late: late period start yr integer\n",
    "    end_late: late period end yr integer\n",
    "    stat: what stat function user wants to run to summarize variables \n",
    "        mean: mean\n",
    "        std: standard deviation\n",
    "        max: max val\n",
    "        min: min val\n",
    "        medium: median\n",
    "    use_anomaly: whether to subtract values from baseline values to find anomaly\n",
    "        True: subtract values\n",
    "        False: don't subtract values \n",
    "    base_start: baseline yr start\n",
    "    base_end: baseline yr end \n",
    "    models_to_run: can specify number of models to run by index of model_list variable\n",
    "        None: all models \n",
    "        [x]: one model to run \n",
    "        [x, x, x...]: whatever number of models to run \n",
    "    file_start_year: ensuring that if time dimension in models starts at 0 or 1, the func will slice the time correctly \n",
    "    \"\"\"\n",
    "    \n",
    "    var_list = [\"tas\", \"tasmax\", \"tasmin\", \"pr\", \"psl\", \"sfcWind\", \"mrsos\"]\n",
    "    if var_idx == \"all\":\n",
    "        varname = var_list\n",
    "        target_indices = list(range(len(var_list)))\n",
    "    else:\n",
    "        target_indices = [var_idx]\n",
    "        # checking var_list for the specific variable index and if the var_idx input is bigger than 6, will give unknown \n",
    "        varname = var_list[var_idx] if var_idx < len(var_list) else \"unknown\"\n",
    "\n",
    "    # making stat dictionary so stat input in func will do correct specified math \n",
    "    stat_map = {\n",
    "        'mean': np.nanmean, 'std': np.nanstd, \n",
    "        'max': np.nanmax, 'min': np.nanmin, 'median': np.nanmedian\n",
    "    }\n",
    "    # variable that will calculate the stat for whatever the user wants and then will default to mean \n",
    "    calc_func = stat_map.get(stat.lower(), np.nanmean)\n",
    "\n",
    "    # runs all models \n",
    "    if models_to_run is None:\n",
    "        selected_models = model_list\n",
    "    # runs one model if user only specified one \n",
    "    elif isinstance(models_to_run, int):\n",
    "        selected_models = [model_list[models_to_run]]\n",
    "    # if none of the above options (all or one) was selected, then was list of models so get those models \n",
    "    else:\n",
    "        selected_models = [model_list[i] for i in models_to_run]\n",
    "\n",
    "    # intilaizing x & y lists \n",
    "    x_list, y_list = [], []\n",
    "    # if in early period, then 0; if in late period, then 1 \n",
    "    periods = [(st_early, end_early, 0), (st_late, end_late, 1)]\n",
    "\n",
    "    print(f\"Variable: {varname} | Stat: {stat} | Anomaly: {use_anomaly}\")\n",
    "\n",
    "    # opening file \n",
    "    for filename in selected_models:\n",
    "        full_path = os.path.join(data_path, filename)\n",
    "        model_short_name = get_model_name(filename)\n",
    "        print(f\"Processing Model: {model_short_name}\")\n",
    "        with nc.Dataset(full_path) as ds:\n",
    "            # slicing data from models to get specific ssp scenario  \n",
    "                # so dimensions should be [ensemble, variable, time, lat, lon]\n",
    "            data_raw = ds[f\"data_{scenario}\"][:]\n",
    "            \n",
    "            # baselines dict to store (mean, std) for each variable --> before processing \n",
    "            baselines = {} \n",
    "            \n",
    "            for v_i in target_indices:\n",
    "                v_name = var_list[v_i]\n",
    "                # extract specific variable data\n",
    "                v_data, _ = convert_units(v_name, data_raw[:, v_i, :, :, :])\n",
    "                \n",
    "                if use_anomaly:\n",
    "                    b_start, b_end = (base_start-file_start_year)*12, (base_end-file_start_year+1)*12\n",
    "                    # historical Mean and StdDev across the time axis\n",
    "                    v_mean = np.nanmean(v_data[:, b_start:b_end, :, :], axis=1)\n",
    "                    v_std = np.nanstd(v_data[:, b_start:b_end, :, :], axis=1)\n",
    "                    # safety check for divide by zero\n",
    "                    v_std[v_std == 0] = 1.0 \n",
    "                    baselines[v_i] = (v_data, v_mean, v_std)\n",
    "                else:\n",
    "                    baselines[v_i] = (v_data, None, None)\n",
    "\n",
    "            # building tensors\n",
    "            for start_yr, end_yr, label in periods:\n",
    "                for yr_idx in range(start_yr, end_yr + 1):\n",
    "                    m_start = (yr_idx - file_start_year) * 12\n",
    "                    m_end = m_start + 12\n",
    "                    \n",
    "                    for ens_idx in range(5):\n",
    "                        # holding the 7 var maps for a given yr/ensemb\n",
    "                        channels = [] \n",
    "                        \n",
    "                        for v_i in target_indices:\n",
    "                            v_data, v_mean, v_std = baselines[v_i]\n",
    "                            \n",
    "                            # slice one trajectory for a yr\n",
    "                            annual_slice = v_data[ens_idx, m_start:m_end, :, :]\n",
    "                            # calculate the yearly summary stat (e.g., mean of the 12 months)\n",
    "                            yearly_val = calc_func(annual_slice, axis=0)\n",
    "                            \n",
    "                            if use_anomaly:\n",
    "                                # standardize via (yearly - hist_mean) / hist_stddev\n",
    "                                val = (yearly_val - v_mean[ens_idx]) / v_std[ens_idx]\n",
    "                            else:\n",
    "                                val = yearly_val\n",
    "                            \n",
    "                            channels.append(val)\n",
    "                        \n",
    "                        # stacking variables on axis 0 to get (7, lat, lon) or (1, lat, lon)\n",
    "                        # this avoids issues run into with .append() on lists\n",
    "                        stacked_channels = np.stack(channels, axis=0)\n",
    "                        x_list.append(stacked_channels)\n",
    "                        y_list.append(label)\n",
    "\n",
    "    # Final array shape: (Samples, Lat, Lon, Channels)\n",
    "    x_data = np.array(x_list)\n",
    "    x_data = x_data.transpose(x_data, (0,2,3,1))\n",
    "    y_data = np.array(y_list).reshape(-1, 1)\n",
    "    \n",
    "    return np.nan_to_num(x_data, nan=0.0), y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d633946",
   "metadata": {},
   "source": [
    "### **plot function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e5aaf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing var_list\n",
    "VAR_LIST = [\"tas\", \"tasmax\", \"tasmin\", \"pr\", \"psl\", \"sfcWind\", \"mrsos\"]\n",
    "\n",
    "# initalizing unit dictionary \n",
    "UNIT_MAP = {\n",
    "    \"tas\": \"°C\", \n",
    "    \"tasmax\": \"°C\", \n",
    "    \"tasmin\": \"°C\", \n",
    "    \"pr\": \"mm/day\", \n",
    "    \"psl\": \"hPa\", \n",
    "    \"sfcWind\": \"m/s\", \n",
    "    \"mrsos\": \"kg/m²\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cb4e42",
   "metadata": {},
   "source": [
    "*this provides a plot calculated from the x_data and y_data tensors from above function. splits x_data into its respective early and late periods using the indices of binary labels from the y_data. values on plot are averages across the values for the early and late periods, besides the third plot which provides the signal (or difference between the early and late periods).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3507b3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffbaae90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_period_comparison(x_data, y_data, var_idx):\n",
    "    # getting variable name for index input \n",
    "    var_name = VAR_LIST[var_idx]\n",
    "    # finding unit for the variable\n",
    "    units = UNIT_MAP.get(var_name, \"units\")\n",
    "    \n",
    "    # looking for the early and late indices in y_data and returns list of row numbers with early and late period indices \n",
    "    early_indices = np.where(y_data == 0)[0]\n",
    "    late_indices = np.where(y_data == 1)[0]\n",
    "    \n",
    "    # calculating the mean values across all years \n",
    "    early_mean = np.mean(x_data[early_indices], axis=0)[0]\n",
    "    late_mean = np.mean(x_data[late_indices], axis=0)[0]\n",
    "    signal = late_mean - early_mean\n",
    "    \n",
    "\n",
    "    # 3 plots on one row \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(22, 6))\n",
    "    titles = [f\"Mean Early ({var_name})\", f\"Mean Late ({var_name})\", \"The Signal (Late - Early)\"]\n",
    "    # transpose so map looks good (would be flipped otherwise)\n",
    "    maps = [early_mean.T, late_mean.T, signal.T]\n",
    "    \n",
    "    # looping three times for each map \n",
    "    for i in range(3):\n",
    "        # if map is for the early/late periods\n",
    "        if i < 2:\n",
    "            # get mins and maxes for color bar\n",
    "            vmin, vmax = np.nanmin(maps[i]), np.nanmax(maps[i])\n",
    "            cmap = 'cool' # specifying a seqeuntial colormap bc i think it looks better? \n",
    "        else:\n",
    "            # making signal plot around zero by making everything absolute value and then finds max (skiping na values)\n",
    "            sig_limit = np.nanmax(np.abs(signal))\n",
    "            # in case signal is 0 (which would crash code), change to 0.1 so that at least everything runs \n",
    "            if sig_limit == 0: sig_limit = 0.1 \n",
    "            # min and max for color bar (all around 0)\n",
    "            vmin, vmax = -sig_limit, sig_limit\n",
    "            cmap = 'RdBu' # specifying diverging colormap \n",
    "        \n",
    "        im = axes[i].imshow(maps[i], origin='lower', cmap=cmap, \n",
    "                            vmin=vmin, vmax=vmax, aspect='auto')\n",
    "        \n",
    "        axes[i].set_title(titles[i])\n",
    "        plt.colorbar(im, ax=axes[i], label=f\"{var_name} ({units})\")\n",
    "        axes[i].set_xlabel(\"Longitude Index\")\n",
    "        axes[i].set_ylabel(\"Latitude Index\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893ab055",
   "metadata": {},
   "source": [
    " for diverging color maps: \n",
    "- https://matplotlib.org/3.1.3/gallery/color/colormap_reference.html \n",
    "\n",
    "for sequential color maps: \n",
    "- https://matplotlib.org/stable/users/explain/colors/colormaps.html\n",
    "- https://matplotlib.org/stable/users/explain/colors/colormaps.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9af28a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: ['tas', 'tasmax', 'tasmin', 'pr', 'psl', 'sfcWind', 'mrsos'] | Stat: mean | Anomaly: True\n",
      "Processing Model: CNRM_ESM2-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v4/nmf8gnpn5vb2t2vlt0df52mh0000gn/T/ipykernel_95666/1600607500.py:96: RuntimeWarning: Mean of empty slice\n",
      "  v_mean = np.nanmean(v_data[:, b_start:b_end, :, :], axis=1)\n",
      "/Users/Caroline/miniconda3/envs/climate/lib/python3.11/site-packages/numpy/lib/nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/var/folders/v4/nmf8gnpn5vb2t2vlt0df52mh0000gn/T/ipykernel_95666/1600607500.py:120: RuntimeWarning: Mean of empty slice\n",
      "  yearly_val = calc_func(annual_slice, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Model: MIROC6\n",
      "Processing Model: MPI-ESM1-2-LR\n",
      "Processing Model: MRI-ESM2-0\n",
      "Processing Model: UKESM1-0-LL\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m x_data_try1, y_data_try1 = \u001b[43mget_cnn_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mssp119\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m sample = plot_period_comparison(x_data_try1, y_data_try1)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 83\u001b[39m, in \u001b[36mget_cnn_tensors\u001b[39m\u001b[34m(model_list, scenario, data_path, var_idx, st_early, end_early, st_late, end_late, stat, use_anomaly, base_start, base_end, models_to_run, file_start_year)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessing Model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_short_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m nc.Dataset(full_path) \u001b[38;5;28;01mas\u001b[39;00m ds:\n\u001b[32m     81\u001b[39m     \u001b[38;5;66;03m# slicing data from models to get specific ssp scenario  \u001b[39;00m\n\u001b[32m     82\u001b[39m         \u001b[38;5;66;03m# so dimensions should be [ensemble, variable, time, lat, lon]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     data_raw = \u001b[43mds\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mscenario\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# baselines dict to store (mean, std) for each variable --> before processing \u001b[39;00m\n\u001b[32m     86\u001b[39m     baselines = {} \n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/netCDF4/_netCDF4.pyx:5150\u001b[39m, in \u001b[36mnetCDF4._netCDF4.Variable.__getitem__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/netCDF4/_netCDF4.pyx:5298\u001b[39m, in \u001b[36mnetCDF4._netCDF4.Variable._toma\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/climate/lib/python3.11/site-packages/numpy/core/_methods.py:55\u001b[39m, in \u001b[36m_any\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, where)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_prod\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     52\u001b[39m           initial=_NoValue, where=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_prod(a, axis, dtype, out, keepdims, initial, where)\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_any\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m, *, where=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m     56\u001b[39m     \u001b[38;5;66;03m# Parsing keyword arguments is currently fairly slow, so avoid it for now\u001b[39;00m\n\u001b[32m     57\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m where \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     58\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m umr_any(a, axis, dtype, out, keepdims)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "x_data_try1, y_data_try1 = get_cnn_tensors(model_list, \"ssp119\", data_path)\n",
    "\n",
    "sample = plot_period_comparison(x_data_try1, y_data_try1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
