{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff961e62",
   "metadata": {},
   "source": [
    "## Data Sources and Import Statements\n",
    "\n",
    "Data have been downloaded from the Earth System Grid Federation at https://esgf-node.ipsl.upmc.fr/projects/esgf-ipsl/.\n",
    "\n",
    "Each file has been concatenated to contain ssp119 and ssp126 scenarios and r1-5 ensemble members from 2015 to 2100. Each has also been regridded to 2.5° resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35d685f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "# IMPORT STATEMENTS\n",
    "\n",
    "# General useful libraries\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "# Loading in data (netcdf files)\n",
    "import h5py\n",
    "# Handling data\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "# Installing xarray and its dependencies\n",
    "import xarray as xr\n",
    "import scipy \n",
    "import dask\n",
    "import bottleneck\n",
    "# Plotting figures\n",
    "import matplotlib.pyplot as plt #Main plotting package\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.util import add_cyclic_point\n",
    "import cartopy.mpl.ticker as cticker\n",
    "\n",
    "# Machine Learning package\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_v2_behavior() \n",
    "print(tf.__version__)\n",
    "\n",
    "# Interpreting neural networks \n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5a753b",
   "metadata": {},
   "source": [
    "## Loading Data/Checking Shape & Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8839b0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lat', 'lon', 'time', 'data_ssp119', 'data_ssp126']\n"
     ]
    }
   ],
   "source": [
    "# Replace this line with the folder in which your clone of the repo is located\n",
    "os.chdir(\"/Users/Caroline/Desktop/school/MamalakisResearch\")\n",
    "\n",
    "base_path = os.getcwd()\n",
    "\n",
    "data_path = base_path + '/data/'\n",
    "\n",
    "# Move to the data folder\n",
    "os.chdir(\"data\")\n",
    "\n",
    "filenames = [\n",
    "    \"CNRM_ESM2-1_ssp119_ssp126_201501_210012_r1-5_2pt5degree.nc\",\n",
    "    \"MIROC6_ssp119_ssp126_201501_210012_r1-5_2pt5degree.nc\",\n",
    "    \"MPI-ESM1-2-LR_ssp119_ssp126_201501_210012_r1-5_2pt5degree.nc\",\n",
    "    \"MRI-ESM2-0_ssp119_ssp126_201501_210012_r1-5_2pt5degree.nc\",\n",
    "    \"UKESM1-0-LL_ssp119_ssp126_201501_210012_r1-5_2pt5degree.nc\",\n",
    "]\n",
    "\n",
    "# We will call upon this later when loading files\n",
    "files = [os.path.join(data_path, f) for f in filenames]\n",
    "\n",
    "ds = nc.Dataset(files[0])\n",
    "print(list(ds.variables.keys()))\n",
    "ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b20a950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_ssp119 shape: (5, 7, 1032, 144, 73)\n",
      "data_ssp126 shape: (5, 7, 1032, 144, 73)\n",
      "data_ssp119 dims: ('ensemble', 'variable', 'time', 'lon', 'lat')\n",
      "data_ssp126 dims: ('ensemble', 'variable', 'time', 'lon', 'lat')\n"
     ]
    }
   ],
   "source": [
    "ds = nc.Dataset(files[0])\n",
    "\n",
    "print(\"data_ssp119 shape:\", ds[\"data_ssp119\"].shape)\n",
    "print(\"data_ssp126 shape:\", ds[\"data_ssp126\"].shape)\n",
    "\n",
    "print(\"data_ssp119 dims:\", ds[\"data_ssp119\"].dimensions)\n",
    "print(\"data_ssp126 dims:\", ds[\"data_ssp126\"].dimensions)\n",
    "\n",
    "ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa1a1502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 234.47755571890667 309.8531804281488 270.3023092874373\n",
      "1 236.21079545127867 322.26223186661866 274.1879111830409\n",
      "2 232.61641495096973 301.92593328821147 266.7963481147974\n",
      "3 2.125162459204466e-12 0.00026221260865620655 1.8725814006290823e-05\n",
      "4 98075.16364846689 103840.45692411123 100618.62371195715\n",
      "5 0.0015542857193698485 12.37257435270109 2.7059935880144472\n",
      "6 3.1505518403209596 45.331031811593704 28.4120984137752\n"
     ]
    }
   ],
   "source": [
    "ds = nc.Dataset(files[1])\n",
    "x = np.array(ds[\"data_ssp119\"][0, :, 0, :, :])  # (7, lon, lat)\n",
    "for j in range(x.shape[0]):\n",
    "    print(j, np.nanmin(x[j]), np.nanmax(x[j]), np.nanmean(x[j]))\n",
    "ds.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8250e9f0",
   "metadata": {},
   "source": [
    "## Variable Index Map and Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f58b1ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable order is explicitly given by metadata:\n",
    "# \"tas, tasmax, tasmin, pr, psl, sfcWind, mrsos\"\n",
    "var_to_index = {\n",
    "    \"tas\": 0,\n",
    "    \"tasmax\": 1,\n",
    "    \"tasmin\": 2,\n",
    "    \"pr\": 3,\n",
    "    \"psl\": 4,\n",
    "    \"sfcWind\": 5,\n",
    "    \"mrsos\": 6,\n",
    "}\n",
    "\n",
    "# Units are also given:\n",
    "var_units = {\n",
    "    \"tas\": \"K\",\n",
    "    \"tasmax\": \"K\",\n",
    "    \"tasmin\": \"K\",\n",
    "    \"pr\": \"kg/m2s\",\n",
    "    \"psl\": \"Pa\",\n",
    "    \"sfcWind\": \"m/s\",\n",
    "    \"mrsos\": \"kg/m2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbee2d8",
   "metadata": {},
   "source": [
    "## Time Handling (Monthly Index → Years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0142cac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(path: str) -> str:\n",
    "    # Everything before \"_ssp...\"\n",
    "    return os.path.basename(path).split(\"_ssp\")[0]\n",
    "\n",
    "\n",
    "def months_to_year_month(time_months: np.ndarray, start_year=2015, start_month=1):\n",
    "    \"\"\"\n",
    "    File says time units are 'months' and it spans 2015-2100.\n",
    "    This creates year + month arrays assuming the first index corresponds to Jan 2015.\n",
    "\n",
    "    If my time axis is \"month count since 2015-01\", this is correct.\n",
    "    If not, it still gives consistent indexing as long as the file starts at 2015-01.\n",
    "    \"\"\"\n",
    "    # time_months is usually 0..1031 or 1..1032 depending on how the file was written but I handle either by shifting to 0-based.\n",
    "    t = np.array(time_months, dtype=int)\n",
    "    if t.min() == 1:\n",
    "        t = t - 1\n",
    "\n",
    "    # compute year/month\n",
    "    year = start_year + (start_month - 1 + t) // 12\n",
    "    month = (start_month - 1 + t) % 12 + 1\n",
    "    return year, month\n",
    "\n",
    "\n",
    "def time_mask_for_year_range(ds: nc.Dataset, start_year: int, end_year: int):\n",
    "    \"\"\"\n",
    "    Create a mask over the monthly time axis using year bounds.\n",
    "    \"\"\"\n",
    "    t = ds[\"time\"][:]\n",
    "    year, month = months_to_year_month(t, start_year=2015, start_month=1)\n",
    "    return (year >= start_year) & (year <= end_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c97e9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(path: str) -> str:\n",
    "    # Everything before \"_ssp...\"\n",
    "    return os.path.basename(path).split(\"_ssp\")[0]\n",
    "\n",
    "\n",
    "def months_to_year_month(time_months: np.ndarray, start_year=2015, start_month=1):\n",
    "    \"\"\"\n",
    "    File says time units are 'months' and it spans 2015-2100.\n",
    "    This creates year + month arrays assuming the first index corresponds to Jan 2015.\n",
    "    \"\"\"\n",
    "    # Cast to numpy array in case it's passed as an xarray DataArray\n",
    "    t = np.array(time_months, dtype=int)\n",
    "    \n",
    "    # Handle 1-based vs 0-based indexing by shifting to 0-based\n",
    "    if t.min() == 1:\n",
    "        t = t - 1\n",
    "\n",
    "    # Compute year/month using floor division and modulo\n",
    "    year = start_year + (start_month - 1 + t) // 12\n",
    "    month = (start_month - 1 + t) % 12 + 1\n",
    "    return year, month\n",
    "\n",
    "\n",
    "def time_mask_for_year_range(ds: xr.Dataset, start_year: int, end_year: int):\n",
    "    \"\"\"\n",
    "    Create a mask over the monthly time axis using year bounds.\n",
    "    \"\"\"\n",
    "    # Using .values to pull the underlying numpy array from the xarray object\n",
    "    t = ds[\"time\"].values\n",
    "    \n",
    "    # Conversion logic\n",
    "    year, month = months_to_year_month(t, start_year=2015, start_month=1)\n",
    "    \n",
    "    # Returning the boolean mask as a numpy array \n",
    "    return (year >= start_year) & (year <= end_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de03746f",
   "metadata": {},
   "source": [
    "## Unit Conversions and Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8bb0b5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_units(varname: str, x: np.ndarray) -> tuple[np.ndarray, str]:\n",
    "    \"\"\"\n",
    "    Convert raw units into more interpretable and plottable units.\n",
    "    - tas/tasmax/tasmin: K to C\n",
    "    - pr: kg/m2s to mm/day  (1 kg/m2 = 1 mm water; multiply by 86400)\n",
    "    - psl: Pa to hPa\n",
    "    - sfcWind: keep m/s\n",
    "    - mrsos: keep kg/m2 \n",
    "    \"\"\"\n",
    "    if varname in {\"tas\", \"tasmax\", \"tasmin\"}:\n",
    "        return x - 273.15, \"°C\"\n",
    "    if varname == \"pr\":\n",
    "        return x * 86400.0, \"mm/day\"\n",
    "    if varname == \"psl\":\n",
    "        return x / 100.0, \"hPa\"\n",
    "    if varname == \"sfcWind\":\n",
    "        return x, \"m/s\"\n",
    "    if varname == \"mrsos\":\n",
    "        return x, \"kg/m²\"\n",
    "    return x, \"unknown\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6f9a88",
   "metadata": {},
   "source": [
    "## Statistics Functions (Mean, Std, Median, Percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48c2f5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stat_over_time(x: np.ndarray, stat: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    x: (ens, time, lat, lon) after loading and swapping\n",
    "    Returns: (ens, lat, lon) after aggregating over time\n",
    "    Supported stats:\n",
    "      - mean (default)\n",
    "      - std\n",
    "      - median\n",
    "      - percentile_XX  (ex. percentile_95)\n",
    "    \"\"\"\n",
    "    s = stat.lower().strip()\n",
    "\n",
    "    if s == \"mean\":\n",
    "        return np.nanmean(x, axis=1)\n",
    "    if s == \"std\":\n",
    "        return np.nanstd(x, axis=1)\n",
    "    if s == \"median\":\n",
    "        return np.nanmedian(x, axis=1)\n",
    "\n",
    "    m = re.match(r\"percentile[_\\s-]?(\\d+)\", s)\n",
    "    if m:\n",
    "        p = float(m.group(1))\n",
    "        return np.nanpercentile(x, p, axis=1)\n",
    "\n",
    "    raise ValueError(f\"Unknown stat '{stat}'. Use mean/std/median/percentile_XX.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d036b20",
   "metadata": {},
   "source": [
    "## Loading and Aggregating Data for One Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4e57c087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def manipulate_dataset(\n",
    "#     varname: str,\n",
    "#     scenario: str,\n",
    "#     model_name: str,\n",
    "#     period: tuple[int, int] | None = (2015, 2100),\n",
    "#     region: tuple[int, int, int, int] | None = None\n",
    "# ): \n",
    "\n",
    "#     \"\"\"\n",
    "#     Opens and manipulates given dataset for a chosen scenario, time period, and region where the inputs are:\n",
    "#       varname: one of tas, tasmax, tasmin, pr, psl, sfcWind, mrsos\n",
    "#       scenario: \"ssp119\" or \"ssp126\"\n",
    "#       model_name: one of 5 models available in data folder\n",
    "#       period: None (default), (start_year, end_year)\n",
    "#       region: entire globe (default), lon/lat range\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Changing to the data folder - for creation of this folder and for data downloading, see data_download script on GitHub\n",
    "#     current_dir = os.getcwd()\n",
    "#     # Add a check\n",
    "#     #if current-dir does not end in \"/data:\"\"\n",
    "#         # os.chdir(current_dir + \"/data\")\n",
    "\n",
    "#     # Scenario check\n",
    "#     scenario = scenario.lower()\n",
    "#     if scenario not in {\"ssp119\", \"ssp126\"}:\n",
    "#         raise ValueError(\"scenario must be 'ssp119' or 'ssp126'\")\n",
    "\n",
    "#     key = f\"data_{scenario}\"\n",
    "#     vidx = var_to_index[varname]\n",
    "\n",
    "#     # Opening dataset \n",
    "#     ds = xr.open_dataset(model_name, engine=\"netcdf4\")\n",
    "\n",
    "\n",
    "    \n",
    "#     # Variable manipulation (Selecting from var_to_index)\n",
    "#     data_array = ds[key].isel(variable=var_to_index[key])\n",
    "\n",
    "#     # Subset time\n",
    "#     if period is not None:\n",
    "#         ya, yb = period\n",
    "#         data_array = data_array.sel(time=slice(str(ya), str(yb)))\n",
    "#     else:\n",
    "#         ya, yb = int(data_array.time[0]), int(data_array.time[-1])\n",
    "        \n",
    "#     # Subset regions\n",
    "#     if region is not None:\n",
    "#         lat1, lat2, lon1, lon2 = region\n",
    "#         data_array = data_array.sel(lat=slice(lat1, lat2), lon=slice(lon1, lon2))\n",
    "    \n",
    "#     # Cosine logic \n",
    "#     cosl = np.cos(np.pi * data_array.lat / 180)\n",
    "    \n",
    "#     # Spatial averaging\n",
    "#     ts = data_array.weighted(cosl).mean(dim=(\"lat\", \"lon\"))\n",
    "#     all_ts.append(ts.compute())\n",
    "\n",
    "#     return ds, ya, yb, lat1, lat2, lon1, lon2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae8cff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manipulate_dataset(\n",
    "    varname: str,\n",
    "    scenario: str,\n",
    "    model_name: str,\n",
    "    period: tuple[int, int] | None = (2015, 2100),\n",
    "    region: tuple[int, int, int, int] | None = None\n",
    "): \n",
    "\n",
    "    \"\"\"\n",
    "    Opens and manipulates given dataset for a chosen scenario, time period, and region.\n",
    "    \"\"\"\n",
    "\n",
    "    # Scenario check\n",
    "    scenario = scenario.lower()\n",
    "    if scenario not in {\"ssp119\", \"ssp126\"}:\n",
    "        raise ValueError(\"scenario must be 'ssp119' or 'ssp126'\")\n",
    "\n",
    "    key = f\"data_{scenario}\"\n",
    "    vidx = var_to_index[varname]\n",
    "\n",
    "    # Opening dataset \n",
    "    ds = xr.open_dataset(model_name, engine=\"netcdf4\")\n",
    "\n",
    "    # Unpacking period tuple and setting up variables\n",
    "    start_year, end_year = period\n",
    "\n",
    "    # Subsetting time\n",
    "    if period is not None:\n",
    "        mask = time_mask_for_year_range(ds, start_year, end_year) \n",
    "        if mask.sum() == 0:\n",
    "            ds.close()\n",
    "            raise ValueError(f\"No months found between {start_year}-{end_year} in {model_name}\")\n",
    "\n",
    "    # Raw shape: (ensemble, var, time, lon, lat)\n",
    "    raw = ds[key].isel(variable=vidx).sel(time=mask)\n",
    "\n",
    "    # Transpose to (ensemble, time, lat, lon) from (ensemble, time, lon, lat) \n",
    "    data_array = raw.transpose(\"ensemble\", \"time\", \"lat\", \"lon\")\n",
    "\n",
    "    # Converting units\n",
    "    data_array, unit_label = convert_units(varname, data_array)\n",
    "\n",
    "    # Subsetting regions\n",
    "    if region is not None:\n",
    "        lat1, lat2, lon1, lon2 = region\n",
    "        data_array = data_array.sel(lat=slice(lat1, lat2), lon=slice(lon1, lon2))\n",
    "    else:\n",
    "        # Define these for the return statement if no region is provided\n",
    "        lat1, lat2, lon1, lon2 = ds.lat.min(), ds.lat.max(), ds.lon.min(), ds.lon.max()\n",
    "    \n",
    "    # Applying cosine logic, thus weighting the average since grid cells get smaller toward the poles\n",
    "    cosl = np.cos(np.pi * data_array.lat / 180)\n",
    "    \n",
    "    # Spatial averaging\n",
    "    ts = data_array.weighted(cosl).mean(dim=(\"lat\", \"lon\"))\n",
    "    processed_data = ts.compute()\n",
    "\n",
    "    ds.close()\n",
    "\n",
    "    # \"Repack\" tuple\n",
    "    region = (float(lat1), float(lat2), float(lon1), float(lon2))\n",
    "\n",
    "    return processed_data, start_year, end_year, region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e3e435",
   "metadata": {},
   "source": [
    "## Time Series Plot\n",
    "\n",
    "Produces a plot of a time series from 2015 to 2100 for the selected variable, scenario, and model. Will show all 5 trajectories within a model. \n",
    "\n",
    "Inputs: \n",
    "- Variable\n",
    "- Scenario\n",
    "- Base period (2015-2100 default)\n",
    "- Region (entire globe default, lon/lat range)\n",
    "- Statistic\n",
    "- Number models returned (all 5 default, single model name) \n",
    "- File name(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "48689e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_plot(\n",
    "    varname: str,\n",
    "    scenario: str,\n",
    "    period: tuple[int, int] | None = (2015, 2100),\n",
    "    region: tuple[int, int, int, int] | None = None,\n",
    "    stat: str = \"mean\",\n",
    "    multimodel: bool = True,\n",
    "    model_name: list[str] | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Produces a time series plot where the inputs are:\n",
    "      varname: one of tas, tasmax, tasmin, pr, psl, sfcWind, mrsos\n",
    "      scenario: \"ssp119\" or \"ssp126\"\n",
    "      period: None (default), (start_year, end_year)\n",
    "      region: entire globe (default), lon/lat range\n",
    "      stat: mean (default), std, median, percentile_XX\n",
    "      multimodel: True (average across all 5 models) (default)\n",
    "      model_name: if not None, ignore multimodel and plot only that/those model(s)\n",
    "    \"\"\"\n",
    "\n",
    "    # Variable check\n",
    "    if varname not in var_to_index:\n",
    "        raise ValueError(f\"varname must be one of {list(var_to_index.keys())}\")\n",
    "    \n",
    "    # Scenario check\n",
    "    scenario = scenario.lower()\n",
    "    if scenario not in {\"ssp119\", \"ssp126\"}:\n",
    "        raise ValueError(\"Scenario must be 'ssp119' or 'ssp126'.\")\n",
    "\n",
    "    # Model name check\n",
    "    # If model name(s) given, filters to only available files\n",
    "    if model_name:\n",
    "        file_list = []\n",
    "        for i in range(len(model_name)):\n",
    "            if model_name[i] in filenames:\n",
    "                file_list.append\n",
    "            else: \n",
    "                raise ValueError(f\"model {model_name[i]} not found. Available: {files}.\")\n",
    "  \n",
    "    # If multimodel (and no model names given)\n",
    "    if multimodel:\n",
    "        pass\n",
    "\n",
    "    # If a model name or names given (and not multimodel)\n",
    "    else:\n",
    "        # Pull variables from manipulate_dataset function\n",
    "        for i in range(len(model_name)): \n",
    "\n",
    "            ds, start_year, end_year, region = manipulate_dataset(varname, scenario, model_name[i], period, region)\n",
    "            \n",
    "            # For years ranging from ya to yb, plot ith element of the list of model names with color pink (C6) and alpha 0.3\n",
    "            plt.plot(np.arange(start_year, end_year), file_list[i], 'C6', alpha=0.3)\n",
    "            # And plot the chosen stat of all models together\n",
    "            ##computed_stat = compute_stat_over_time(model_name[i], stat)\n",
    "            #plt.plot(np.arange(start_year, end_year), computed_stat, 'C6',alpha=0.3)\n",
    "            \n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        plt.axis('tight')\n",
    "        plt.grid(color='0.8')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        ds.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a8c453dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m    \u001b[38;5;66;03m# Example 1: Time-series of tas in ssp119 scenario\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43mtime_series_plot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvarname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtas\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscenario\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mssp119\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mperiod\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2020\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2039\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mregion\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m80\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m80\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstat\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmultimodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCNRM_ESM2-1_ssp119_ssp126_201501_210012_r1-5_2pt5degree.nc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 52\u001b[39m, in \u001b[36mtime_series_plot\u001b[39m\u001b[34m(varname, scenario, period, region, stat, multimodel, model_name)\u001b[39m\n\u001b[32m     49\u001b[39m     ds, start_year, end_year, region = manipulate_dataset(varname, scenario, model_name[i], period, region)\n\u001b[32m     51\u001b[39m     \u001b[38;5;66;03m# For years ranging from ya to yb, plot ith element of the list of model names with color pink (C6) and alpha 0.3\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     plt.plot(np.arange(start_year, end_year), \u001b[43mfile_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m, \u001b[33m'\u001b[39m\u001b[33mC6\u001b[39m\u001b[33m'\u001b[39m, alpha=\u001b[32m0.3\u001b[39m)\n\u001b[32m     53\u001b[39m     \u001b[38;5;66;03m# And plot the chosen stat of all models together\u001b[39;00m\n\u001b[32m     54\u001b[39m     \u001b[38;5;66;03m##computed_stat = compute_stat_over_time(model_name[i], stat)\u001b[39;00m\n\u001b[32m     55\u001b[39m     \u001b[38;5;66;03m#plt.plot(np.arange(start_year, end_year), computed_stat, 'C6',alpha=0.3)\u001b[39;00m\n\u001b[32m     57\u001b[39m plt.xlabel(\u001b[33m'\u001b[39m\u001b[33mx\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "   # Example 1: Time-series of tas in ssp119 scenario\n",
    "    time_series_plot(\n",
    "        varname=\"tas\",\n",
    "        scenario=\"ssp119\", \n",
    "        period=(2020, 2039), \n",
    "        region=(-80, 80, 100, 200),\n",
    "        stat=\"mean\",\n",
    "        multimodel=False,\n",
    "        model_name = [\"CNRM_ESM2-1_ssp119_ssp126_201501_210012_r1-5_2pt5degree.nc\"]\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mamalakis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
